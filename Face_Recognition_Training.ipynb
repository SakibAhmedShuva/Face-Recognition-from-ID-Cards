{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jo3YIfsez9ut"
      },
      "source": [
        "## Installing and importing face_recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzwlHBittx1t",
        "outputId": "4b77f545-c41f-42c8-9b6d-1d609227a2f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting imutils\n",
            "  Downloading imutils-0.5.4.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Building wheels for collected packages: imutils\n",
            "  Building wheel for imutils (setup.py): started\n",
            "  Building wheel for imutils (setup.py): finished with status 'done'\n",
            "  Created wheel for imutils: filename=imutils-0.5.4-py3-none-any.whl size=25853 sha256=1b513c90c20ec77d6f6a19711a7403153a24f4545f73405a5d3dd98ac8f14a4d\n",
            "  Stored in directory: c:\\users\\sakib ahmed\\appdata\\local\\pip\\cache\\wheels\\5b\\76\\96\\ad0c321506837bef578cf3008df3916c23018435a355d9f6b1\n",
            "Successfully built imutils\n",
            "Installing collected packages: imutils\n",
            "Successfully installed imutils-0.5.4\n"
          ]
        }
      ],
      "source": [
        "#!pip install dlib\n",
        "#!pip install face_recognition\n",
        "#!pip install imutils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "YOUV-9vst_r7"
      },
      "outputs": [],
      "source": [
        "import dlib\n",
        "import face_recognition\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "import imutils\n",
        "import matplotlib.pyplot as plt\n",
        "#from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkayEejc9aKv"
      },
      "source": [
        "## Encoding faces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "kRSky1crvHd6"
      },
      "outputs": [],
      "source": [
        "photo_01 = face_recognition.load_image_file(r'.\\data\\cropped_images\\Tanvir Mahtab.jpg')\n",
        "photo_01_encoding = face_recognition.face_encodings(photo_01)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hzl-hpLevaaM",
        "outputId": "82e128a7-e145-49d9-dd60-b7801c1e4c60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(photo_01_encoding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "ScMsYX5dvyiA"
      },
      "outputs": [],
      "source": [
        "unknown_photo = face_recognition.load_image_file(r'.\\data\\cropped_images\\test\\test 2.jpg')\n",
        "unknown_encoding = face_recognition.face_encodings(unknown_photo)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8JLOjnQwX3b",
        "outputId": "0cd6fc2c-e498-4c20-df98-4a92920932b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[False]\n"
          ]
        }
      ],
      "source": [
        "results = face_recognition.compare_faces([photo_01_encoding], unknown_encoding)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "RcuxAssSy9aC"
      },
      "outputs": [],
      "source": [
        "photo_02 = face_recognition.load_image_file(r'.\\data\\cropped_images\\Ahmad Nakib.jpg')\n",
        "photo_02_encoding = face_recognition.face_encodings(photo_02)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "3aOUB5plzQM9"
      },
      "outputs": [],
      "source": [
        "list_encodings = [photo_01_encoding, photo_02_encoding]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "D0kuu6B4zXrG"
      },
      "outputs": [],
      "source": [
        "list_names = ['Tanvir Mahtab', 'Ahmad Nakib']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "OmWSM_iyziFS"
      },
      "outputs": [],
      "source": [
        "test_image = cv2.imread(r'.\\data\\cropped_images\\test\\test 1.jpg')\n",
        "image_rgb = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
        "face_locations = face_recognition.face_locations(image_rgb, model = 'hog')\n",
        "face_encoding = face_recognition.face_encodings(image_rgb, face_locations)\n",
        "face_encoding = face_encoding[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lhlFjHI0haE",
        "outputId": "e396a542-a9c7-42eb-e781-75c1a5c5d89e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[True, True]\n"
          ]
        }
      ],
      "source": [
        "results = face_recognition.compare_faces(list_encodings, face_encoding)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The above codes are showing false positives. So I have implemented the following solution (np.argmin for minimum face distances):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n54-EWll1QjI",
        "outputId": "c03a75e4-3cdc-4112-f0af-e644d8be4aab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.40505838 0.59486724]\n"
          ]
        }
      ],
      "source": [
        "face_distances = face_recognition.face_distance(list_encodings, face_encoding)\n",
        "print(face_distances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ip9EhlsM1d-Z",
        "outputId": "a75ad33a-8a48-4a5b-bff9-935cf1b2e11d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 146,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_match_index = np.argmin(face_distances)\n",
        "best_match_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 772
        },
        "id": "ErtK-6Mn1n8b",
        "outputId": "c2fbeef7-ae05-488e-c4e6-b622336c28f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ahmad Nakib is in this picture\n",
            "0.4050583821332193\n"
          ]
        }
      ],
      "source": [
        "if results[best_match_index]:\n",
        "  pred = list_names[best_match_index]\n",
        "  print(pred + ' is in this picture')\n",
        "  cv2.imshow('Test Image', test_image)\n",
        "  cv2.waitKey(0)\n",
        "  cv2.destroyAllWindows()\n",
        "  print(face_distances[best_match_index])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPJvPMJKQT_F"
      },
      "source": [
        "## Encoding all image's faces from a specific path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GA1W-zCM5aBe",
        "outputId": "acac8764-aa38-430f-a862-f9c09bba1111"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['./data/cropped_images\\\\Ahmad Nakib.jpg', './data/cropped_images\\\\Tanvir Mahtab.jpg']\n"
          ]
        }
      ],
      "source": [
        "paths = [os.path.join('./data/cropped_images', f) for f in os.listdir('./data/cropped_images') if f.endswith('.jpg')]\n",
        "print(paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "CpHiSZqQ5wfv"
      },
      "outputs": [],
      "source": [
        "def get_encodings(paths):\n",
        "  print('{} images found'.format(len(paths)))\n",
        "  list_encodings = []\n",
        "  list_names = []\n",
        "  for img_path in paths:\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    basename = os.path.basename(img_path)\n",
        "    #print(basename)\n",
        "    (name, ext) = os.path.splitext(basename)\n",
        "    #print(name, ext)\n",
        "    face_roi = face_recognition.face_locations(img, model = 'cnn') # hog\n",
        "    face_encoding = face_recognition.face_encodings(img, face_roi)[0]\n",
        "    if len(face_encoding) > 0:\n",
        "      list_encodings.append(face_encoding)\n",
        "      list_names.append(name)\n",
        "    else:\n",
        "      print('Could not detect the face from image {}'.format(img_path))\n",
        "  return list_encodings, list_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wv2JbIdm57FK",
        "outputId": "0bfd5172-a38d-4f6a-b864-a9b39d02b4db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2 images found\n"
          ]
        }
      ],
      "source": [
        "list_encodings, list_names = get_encodings(paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OacLQwsE7qdi",
        "outputId": "4e4ee932-53d0-4258-d91d-c7dbaaa18205"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2, 2)"
            ]
          },
          "execution_count": 152,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(list_encodings), len(list_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8l77nI57vFY",
        "outputId": "8f01134f-db25-49f0-ed2b-26d29ad36711"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Ahmad Nakib', 'Tanvir Mahtab']"
            ]
          },
          "execution_count": 153,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "ZDng1_3073Hc"
      },
      "outputs": [],
      "source": [
        "#list_encodings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "wVNHbbu_78lt"
      },
      "outputs": [],
      "source": [
        "def recognize_faces(image, list_encodings, list_names, tolerance = 0.6):\n",
        "  img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  face_locations = face_recognition.face_locations(img_rgb)\n",
        "  face_encodings = face_recognition.face_encodings(img_rgb, face_locations)\n",
        "  face_names = []\n",
        "  conf_values = []\n",
        "  for encoding in face_encodings:\n",
        "    matches = face_recognition.compare_faces(list_encodings, encoding, tolerance = tolerance)\n",
        "    name = 'Not identified'\n",
        "    face_distances = face_recognition.face_distance(list_encodings, encoding)\n",
        "    best_match_index = np.argmin(face_distances)\n",
        "    if matches[best_match_index]:\n",
        "      name = list_names[best_match_index]\n",
        "    face_names.append(name)\n",
        "    conf_values.append(face_distances[best_match_index])\n",
        "  face_locations = np.array(face_locations)\n",
        "  return face_locations.astype(int), face_names, conf_values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yEAOUNzGT32"
      },
      "source": [
        "## Display recognition above bounding box\n",
        "\n",
        "- Coordinates are returned in this order: top, right, bottom, left ([ref](https://face-recognition.readthedocs.io/en/latest/face_recognition.html#face_recognition.api.face_locations))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "8IrBYO1v_VCj"
      },
      "outputs": [],
      "source": [
        "test_image = cv2.imread(r'.\\data\\cropped_images\\test\\test 1.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "HnJnldWT_uVp"
      },
      "outputs": [],
      "source": [
        "face_locations, face_names, conf_values = recognize_faces(test_image, list_encodings, list_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6KyzERAAkkB",
        "outputId": "df6371d7-b380-488c-a833-94a281717aac"
      },
      "outputs": [],
      "source": [
        "#face_locations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIun9esMApHM",
        "outputId": "a31a03a6-3e9e-4c7b-8cd1-48add4d35a0a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Tanvir Mahtab']"
            ]
          },
          "execution_count": 159,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "face_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GGRZQgrAtO_",
        "outputId": "72acbb69-358e-4f54-ad0e-9644da8b4010"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.4315571251918219]"
            ]
          },
          "execution_count": 160,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conf_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "id": "NILW4xArA0GE",
        "outputId": "8ac624f3-02f2-4465-fe9a-4b70f357bf1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.4315571251918219\n"
          ]
        }
      ],
      "source": [
        "for face_loc, name, conf in zip(face_locations, face_names, conf_values):\n",
        "  y1, x2, y2, x1 = face_loc[0], face_loc[1], face_loc[2], face_loc[3]\n",
        "  cv2.putText(test_image, name, (x1, y1 - 10), cv2.FONT_HERSHEY_DUPLEX, 0.8, (0,0,255), 2)\n",
        "  cv2.rectangle(test_image, (x1, y1), (x2, y2), (0,10,255), 4)\n",
        "  print(conf)\n",
        "cv2.imshow('Test_Image', test_image)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Putting everything under a single function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "cfAIgkdABzXr"
      },
      "outputs": [],
      "source": [
        "def show_recognition(test_image, list_encodings, list_names, max_width=700, tolerance=0.6):\n",
        "  face_locations, face_names, conf_values = recognize_faces(test_image, list_encodings, list_names, tolerance)\n",
        "\n",
        "  for face_loc, name, conf in zip(face_locations, face_names, conf_values):\n",
        "    y1, x2, y2, x1 = face_loc[0], face_loc[1], face_loc[2], face_loc[3]\n",
        "\n",
        "    cv2.putText(test_image, name,(x1, y1 - 10), cv2.FONT_HERSHEY_DUPLEX, 0.8, (0, 0, 255), 2)\n",
        "    cv2.rectangle(test_image, (x1, y1), (x2, y2), (0, 10, 255), 4)\n",
        "    print(conf)\n",
        "\n",
        "  if (test_image.shape[1] > max_width):\n",
        "    test_image = imutils.resize(test_image, width=max_width)\n",
        "  cv2.imshow('Test_Image',test_image)\n",
        "  cv2.waitKey(0)\n",
        "  cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        },
        "id": "XfEaaLT5CGR4",
        "outputId": "492f5ede-7ae0-4f39-96b9-681c98d551dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5194259466244441\n"
          ]
        }
      ],
      "source": [
        "test_image = cv2.imread(r'.\\data\\cropped_images\\test\\test 2.jpg')\n",
        "show_recognition(test_image, list_encodings, list_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RESTzXvZQiD9"
      },
      "source": [
        "### Recognize all faces from path\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0WcgBa_DGy7",
        "outputId": "84c03431-3162-43d2-f245-d0ab556f949b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['.\\\\data\\\\cropped_images\\\\test\\\\test 1.jpg',\n",
              " '.\\\\data\\\\cropped_images\\\\test\\\\test 2.jpg',\n",
              " '.\\\\data\\\\cropped_images\\\\test\\\\test 3.jpg']"
            ]
          },
          "execution_count": 172,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path_test = r\".\\data\\cropped_images\\test\"\n",
        "images_test = [os.path.join(path_test, f) for f in os.listdir(path_test)]\n",
        "images_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "t9vWy1MuDI1q",
        "outputId": "6dab4a06-44a7-42f9-ad95-8b53dca19a04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".\\data\\cropped_images\\test\\test 1.jpg\n",
            "0.4315571251918219\n",
            ".\\data\\cropped_images\\test\\test 2.jpg\n",
            "0.5194259466244441\n",
            ".\\data\\cropped_images\\test\\test 3.jpg\n",
            "0.4084710124456488\n"
          ]
        }
      ],
      "source": [
        "for image_path in images_test:\n",
        "  print(image_path)\n",
        "  test_image = cv2.imread(image_path)\n",
        "  show_recognition(test_image, list_encodings, list_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2k9ADBsISXsI"
      },
      "source": [
        "### Storing and loading encodings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "s-fcXrSwEkcd"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "pickle_name = \"user_list.pickle\"\n",
        "encodings_data = {\"encodings\": list_encodings, \"names\": list_names}\n",
        "f = open(pickle_name, \"wb\")\n",
        "f.write(pickle.dumps(encodings_data))\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "F-Fkpd7HErke"
      },
      "outputs": [],
      "source": [
        "data_encoding = pickle.loads(open(pickle_name, \"rb\").read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "j2Li_P6uEtcP"
      },
      "outputs": [],
      "source": [
        "list_encodings = data_encoding[\"encodings\"]\n",
        "list_names = data_encoding[\"names\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzGsiLoZEvU0",
        "outputId": "99409578-eb1f-4236-eaab-87f331db67df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(list_encodings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4ZYLkJ40dKx"
      },
      "source": [
        "### Test recognition on image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "MQhPorFCEyRG",
        "outputId": "7ad4f566-4a12-4f8a-9d7c-35641c7ff922"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5194259466244441\n"
          ]
        }
      ],
      "source": [
        "image_path = r'.\\data\\cropped_images\\test\\test 2.jpg'\n",
        "test_image = cv2.imread(image_path)\n",
        "show_recognition(test_image, list_encodings, list_names)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
