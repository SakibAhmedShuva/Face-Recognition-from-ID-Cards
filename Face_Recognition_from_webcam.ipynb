{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15Pxpv9altqT"
      },
      "source": [
        "## Install / Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODdtiZnKh3gq",
        "outputId": "d95ef3bb-2dad-4977-94e6-f9db1eabb146"
      },
      "outputs": [],
      "source": [
        "#!pip install face_recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gDxL_j5PQvUc"
      },
      "outputs": [],
      "source": [
        "import face_recognition\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import numpy as np\n",
        "import pickle\n",
        "#from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCeA-8FIpkEs"
      },
      "source": [
        "## Load encodings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "B-ZLSN8KZzt8"
      },
      "outputs": [],
      "source": [
        "pickle_name = \"brain.pickle\"\n",
        "data_encoding = pickle.loads(open(pickle_name, \"rb\").read())\n",
        "list_encodings = data_encoding[\"encodings\"]\n",
        "list_names = data_encoding[\"names\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "resizing = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def recognize_faces(image, list_encodings, list_names, resizing=0.25, tolerance=0.6):\n",
        "  image = cv2.resize(image, (0, 0), fx=resizing, fy=resizing)\n",
        "\n",
        "  img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  face_locations = face_recognition.face_locations(img_rgb)\n",
        "  face_encodings = face_recognition.face_encodings(img_rgb, face_locations)\n",
        "\n",
        "  face_names = []\n",
        "  conf_values = []\n",
        "  for encoding in face_encodings:\n",
        "    matches = face_recognition.compare_faces(list_encodings, encoding, tolerance=tolerance)\n",
        "    name = \"Not identified\"\n",
        "\n",
        "    face_distances = face_recognition.face_distance(list_encodings, encoding)\n",
        "    best_match_index = np.argmin(face_distances)\n",
        "    if matches[best_match_index]:\n",
        "      name = list_names[best_match_index]\n",
        "    face_names.append(name)\n",
        "    conf_values.append(face_distances[best_match_index])\n",
        "\n",
        "  face_locations = np.array(face_locations)\n",
        "  # we are scalig back up the face locations, since the frame we detected was scaled by the scaleFactor of `resizing` variable\n",
        "  face_locations = face_locations / resizing\n",
        "  return face_locations.astype(int), face_names, conf_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_recognition(frame, face_locations, face_names, conf_values):\n",
        "\n",
        "  for face_loc, name, conf in zip(face_locations, face_names, conf_values):\n",
        "    y1, x2, y2, x1 = face_loc[0], face_loc[1], face_loc[2], face_loc[3]\n",
        "\n",
        "    conf = \"{:.8f}\".format(conf)\n",
        "    cv2.putText(frame, name,(x1, y1 - 10), cv2.FONT_HERSHEY_DUPLEX, 0.7, (20, 255, 0), 2, lineType=cv2.LINE_AA)\n",
        "    cv2.rectangle(frame, (x1, y1), (x2, y2), (20, 255, 0), 4)\n",
        "    if name != \"Not identified\":\n",
        "        cv2.putText(frame, conf,(x1, y2 + 15), cv2.FONT_HERSHEY_DUPLEX, 0.5, (20, 255, 0), 1, lineType=cv2.LINE_AA)\n",
        "\n",
        "  return frame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IE-F6Rd2p4Rh"
      },
      "source": [
        "## Processing the video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "f0-Gn0u5p_sE"
      },
      "outputs": [],
      "source": [
        "frames_show = 24\n",
        "current_frame = 1\n",
        "max_frames = -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Capturing video from Webcam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# Initialize video capture\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "# Check if the camera opened successfully\n",
        "if not cap.isOpened():\n",
        "    print(\"Error: Could not open camera.\")\n",
        "    exit()\n",
        "\n",
        "# Defining video output parameters\n",
        "video_width = 640  \n",
        "video_height = 480  \n",
        "fps = 30 \n",
        "video_output = cv2.VideoWriter('output.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (video_width, video_height))\n",
        "\n",
        "# Setting maximum number of frames to process (-1 for unlimited)\n",
        "max_frames = -1\n",
        "\n",
        "# Setting maximum width for resizing (-1 to disable resizing)\n",
        "max_width = None\n",
        "\n",
        "frames_show = 10  # Number of frames to show\n",
        "\n",
        "current_frame = 0\n",
        "\n",
        "while (cv2.waitKey(1) < 0):\n",
        "    connected, frame = cap.read()\n",
        "\n",
        "    if not connected:\n",
        "        break\n",
        "\n",
        "    if max_frames > -1 and current_frame > max_frames:\n",
        "        break\n",
        "\n",
        "    (H, W) = frame.shape[:2]\n",
        "\n",
        "    t = time.time()\n",
        "\n",
        "    # Resizing frame\n",
        "    if max_width is not None and W > max_width:\n",
        "        frame = cv2.resize(frame, (video_width, video_height))\n",
        "\n",
        "    # Perform face recognition\n",
        "    face_locations, face_names, conf_values = recognize_faces(frame, list_encodings, list_names, resizing)\n",
        "    frame = show_recognition(frame, face_locations, face_names, conf_values)\n",
        "\n",
        "    # Display processing time\n",
        "    cv2.putText(frame, \"Frame processed in {:.2f} seconds\".format(time.time() - t), (20, video_height-20), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (250, 250, 250), 0, lineType=cv2.LINE_AA)\n",
        "\n",
        "    # Write frame to video output\n",
        "    video_output.write(frame)\n",
        "\n",
        "    # Display resized frame\n",
        "    if current_frame <= frames_show:\n",
        "        cv2.imshow('Resized Image', cv2.resize(frame, (0, 0), fx=0.75, fy=0.75))\n",
        "\n",
        "    current_frame += 1\n",
        "\n",
        "print(\"Finished\")\n",
        "video_output.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
