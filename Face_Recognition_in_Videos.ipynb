{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15Pxpv9altqT"
      },
      "source": [
        "## Install / Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODdtiZnKh3gq",
        "outputId": "d95ef3bb-2dad-4977-94e6-f9db1eabb146"
      },
      "outputs": [],
      "source": [
        "#!pip install face_recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gDxL_j5PQvUc"
      },
      "outputs": [],
      "source": [
        "import face_recognition\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import numpy as np\n",
        "import pickle\n",
        "#from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCeA-8FIpkEs"
      },
      "source": [
        "## Load encodings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "B-ZLSN8KZzt8"
      },
      "outputs": [],
      "source": [
        "pickle_name = \"brain.pickle\"\n",
        "data_encoding = pickle.loads(open(pickle_name, \"rb\").read())\n",
        "list_encodings = data_encoding[\"encodings\"]\n",
        "list_names = data_encoding[\"names\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF54_3gSmbJF"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NYMC0xTdRfnG"
      },
      "outputs": [],
      "source": [
        "max_width = 900"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zZoVnnqkRetI"
      },
      "outputs": [],
      "source": [
        "def resize_video(width, height, max_width = 600):\n",
        "  if (width > max_width):\n",
        "    proportion = width / height\n",
        "    video_width = max_width\n",
        "    video_height = int(video_width / proportion)\n",
        "  else:\n",
        "    video_width = width\n",
        "    video_height = height\n",
        "\n",
        "  return video_width, video_height"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KHmn2LoFgNcM"
      },
      "outputs": [],
      "source": [
        "resizing = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wlgRUCsYaEo8"
      },
      "outputs": [],
      "source": [
        "def recognize_faces(image, list_encodings, list_names, resizing=0.25, tolerance=0.6):\n",
        "  image = cv2.resize(image, (0, 0), fx=resizing, fy=resizing)\n",
        "\n",
        "  img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  face_locations = face_recognition.face_locations(img_rgb)\n",
        "  face_encodings = face_recognition.face_encodings(img_rgb, face_locations)\n",
        "\n",
        "  face_names = []\n",
        "  conf_values = []\n",
        "  for encoding in face_encodings:\n",
        "    matches = face_recognition.compare_faces(list_encodings, encoding, tolerance=tolerance)\n",
        "    name = \"Not identified\"\n",
        "\n",
        "    face_distances = face_recognition.face_distance(list_encodings, encoding)\n",
        "    best_match_index = np.argmin(face_distances)\n",
        "    if matches[best_match_index]:\n",
        "      name = list_names[best_match_index]\n",
        "    face_names.append(name)\n",
        "    conf_values.append(face_distances[best_match_index])\n",
        "\n",
        "  face_locations = np.array(face_locations)\n",
        "  # we are scalig back up the face locations, since the frame we detected was scaled by the scaleFactor of `resizing` variable\n",
        "  face_locations = face_locations / resizing\n",
        "  return face_locations.astype(int), face_names, conf_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "x9N5dKrvBoMX"
      },
      "outputs": [],
      "source": [
        "def show_recognition(frame, face_locations, face_names, conf_values):\n",
        "\n",
        "  for face_loc, name, conf in zip(face_locations, face_names, conf_values):\n",
        "    y1, x2, y2, x1 = face_loc[0], face_loc[1], face_loc[2], face_loc[3]\n",
        "\n",
        "    conf = \"{:.8f}\".format(conf)\n",
        "    cv2.putText(frame, name,(x1, y1 - 10), cv2.FONT_HERSHEY_DUPLEX, 0.7, (20, 255, 0), 2, lineType=cv2.LINE_AA)\n",
        "    cv2.rectangle(frame, (x1, y1), (x2, y2), (20, 255, 0), 4)\n",
        "    if name != \"Not identified\":\n",
        "        cv2.putText(frame, conf,(x1, y2 + 15), cv2.FONT_HERSHEY_DUPLEX, 0.5, (20, 255, 0), 1, lineType=cv2.LINE_AA)\n",
        "\n",
        "  return frame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9HRBJXDnqfZ"
      },
      "source": [
        "## Video Configurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mt2Dim2jRk3R"
      },
      "outputs": [],
      "source": [
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "fps = 30"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84Lk6OCdoQRX"
      },
      "source": [
        "## Reading the video file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tc_h7yzaRDIK",
        "outputId": "8f59144f-b772-4332-b2dd-ab448b14ab6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "402 850\n"
          ]
        }
      ],
      "source": [
        "video_file = r\".\\data\\cropped_images\\test\\Video.mp4\"\n",
        "result_file = 'result.avi'\n",
        "\n",
        "cap = cv2.VideoCapture(video_file)\n",
        "connected, video = cap.read()\n",
        "video_width, video_height = video.shape[1], video.shape[0]\n",
        "\n",
        "if max_width is not None:\n",
        "  video_width, video_height = resize_video(video_width, video_height, max_width)\n",
        "print(video_width, video_height)\n",
        "\n",
        "video_output = cv2.VideoWriter(result_file, fourcc, fps, (video_width, video_height))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IE-F6Rd2p4Rh"
      },
      "source": [
        "## Processing the video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "f0-Gn0u5p_sE"
      },
      "outputs": [],
      "source": [
        "frames_show = 24\n",
        "current_frame = 1\n",
        "max_frames = -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Face Recognition in Videos  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "while (cv2.waitKey(1) < 0):\n",
        "  connected, frame = cap.read() \n",
        "\n",
        "  if not connected:\n",
        "    break  \n",
        "  \n",
        "  if max_frames > -1 and current_frame > max_frames:\n",
        "      break   \n",
        "  \n",
        "  (H, W) = frame.shape[:2] \n",
        "  \n",
        "  t = time.time() \n",
        "\n",
        "  if max_width is not None: \n",
        "    frame = cv2.resize(frame, (video_width, video_height)) \n",
        "\n",
        "  face_locations, face_names, conf_values = recognize_faces(frame, list_encodings, list_names, resizing)\n",
        "  frame = show_recognition(frame, face_locations, face_names, conf_values)\n",
        "                          \n",
        "  cv2.putText(frame, \" frame processed in {:.2f} seconds\".format(time.time() - t), (20, video_height-20), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (250, 250, 250), 0, lineType=cv2.LINE_AA)  # cv2.LINE_AA to improve the quality of the text\n",
        "\n",
        "  video_output.write(frame) \n",
        "\n",
        "  if current_frame <= frames_show:\n",
        "    cv2.imshow('Resized Image', cv2.resize(frame, (0, 0), fx=0.75, fy=0.75))\n",
        "\n",
        "  current_frame + 1 \n",
        "\n",
        "print(\"Finished\")\n",
        "video_output.release() \n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
